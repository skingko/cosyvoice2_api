#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
CosyVoice2 ä¸“ç”¨TTSæœåŠ¡
ä¼˜åŒ–çš„é«˜æ€§èƒ½è¯­éŸ³åˆæˆæœåŠ¡ï¼Œä¸“é—¨é’ˆå¯¹CosyVoice2æ¨¡å‹è¿›è¡Œä¼˜åŒ–
"""

import asyncio
import os
import sys
import uuid
import tempfile
import json
import hashlib
import mimetypes
from pathlib import Path
from typing import List, Dict, Optional, AsyncGenerator, Union, Any
from dataclasses import dataclass
from enum import Enum
import logging
import librosa

# æ·»åŠ CosyVoiceæ¨¡å—è·¯å¾„
sys.path.append('CosyVoice')

# éŸ³é¢‘å¤„ç†
import torch
import torchaudio
import numpy as np

# ç½‘ç»œè¯·æ±‚
import aiohttp
import aiofiles

# é…ç½®
from config import get_config

# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AudioFormat(Enum):
    """éŸ³é¢‘æ ¼å¼æšä¸¾"""
    WAV = "wav"
    MP3 = "mp3"
    FLAC = "flac"

class SynthesisMode(Enum):
    """åˆæˆæ¨¡å¼æšä¸¾"""
    BASIC = "basic"           # åŸºç¡€åˆæˆ
    ZERO_SHOT = "zero_shot"   # é›¶æ ·æœ¬éŸ³è‰²å…‹éš†
    CROSS_LINGUAL = "cross_lingual"  # è·¨è¯­è¨€åˆæˆ
    INSTRUCT = "instruct"     # æŒ‡ä»¤å¼åˆæˆ
    INSTRUCT2 = "instruct2"   # CosyVoice2è‡ªç„¶è¯­è¨€æ§åˆ¶
    VOICE_CONVERSION = "voice_conversion"  # è¯­éŸ³è½¬æ¢

@dataclass
class TTSRequest:
    """TTSè¯·æ±‚ç±»"""
    def __init__(self, text: str, mode: SynthesisMode = SynthesisMode.BASIC,
                 speaker: str = None, language: str = "zh", speed: float = 1.0,
                 format: AudioFormat = AudioFormat.WAV, sample_rate: int = None,
                 prompt_text: str = None, prompt_audio = None, instruct_text: str = None,
                 stream: bool = False, text_frontend: bool = True, zero_shot_spk_id: str = "",
                 seed: int = None):
        self.text = text
        self.mode = mode
        self.speaker = speaker
        self.language = language
        self.speed = speed
        self.format = format
        self.sample_rate = sample_rate or 22050
        self.prompt_text = prompt_text
        self.prompt_audio = prompt_audio
        self.instruct_text = instruct_text
        self.stream = stream
        self.text_frontend = text_frontend
        self.zero_shot_spk_id = zero_shot_spk_id
        self.seed = seed

@dataclass
class TTSResult:
    """TTS ç»“æœæ•°æ®ç±»"""
    success: bool
    audio_file: Optional[str] = None
    audio_data: Optional[bytes] = None  # ç”¨äºæµå¼ä¼ è¾“
    duration: Optional[float] = None
    file_size: Optional[int] = None
    sample_rate: Optional[int] = None
    error_message: Optional[str] = None
    request_id: Optional[str] = None
    mode_used: Optional[SynthesisMode] = None
    speaker_used: Optional[str] = None

class AudioFileHandler:
    """éŸ³é¢‘æ–‡ä»¶å¤„ç†å™¨"""
    
    @staticmethod
    async def process_audio_input(audio_input: Union[str, bytes, Path]) -> str:
        """
        å¤„ç†éŸ³é¢‘è¾“å…¥ï¼Œç»Ÿä¸€è½¬æ¢ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
        æ”¯æŒ: æœ¬åœ°æ–‡ä»¶è·¯å¾„ã€ç½‘ç»œURLã€å­—èŠ‚æ•°æ®
        """
        if isinstance(audio_input, (str, Path)):
            audio_path = str(audio_input)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç½‘ç»œURL
            if audio_path.startswith(('http://', 'https://')):
                return await AudioFileHandler._download_audio(audio_path)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶
            elif os.path.exists(audio_path):
                return os.path.abspath(audio_path)
            
            else:
                raise ValueError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        elif isinstance(audio_input, bytes):
            return await AudioFileHandler._save_audio_bytes(audio_input)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘è¾“å…¥ç±»å‹: {type(audio_input)}")

    @staticmethod
    async def _download_audio(url: str) -> str:
        """ä¸‹è½½ç½‘ç»œéŸ³é¢‘æ–‡ä»¶"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        # ä»URLæˆ–Content-Typeæ¨æ–­æ–‡ä»¶æ‰©å±•å
                        content_type = response.headers.get('content-type', '')
                        extension = mimetypes.guess_extension(content_type) or '.wav'
                        
                        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                        temp_file = tempfile.NamedTemporaryFile(suffix=extension, delete=False)
                        async with aiofiles.open(temp_file.name, 'wb') as f:
                            async for chunk in response.content.iter_chunked(8192):
                                await f.write(chunk)
                        
                        logger.info(f"éŸ³é¢‘ä¸‹è½½æˆåŠŸ: {url} -> {temp_file.name}")
                        return temp_file.name
                    else:
                        raise ValueError(f"ä¸‹è½½å¤±è´¥: HTTP {response.status}")
        except Exception as e:
            raise ValueError(f"éŸ³é¢‘ä¸‹è½½å¤±è´¥: {e}")

    @staticmethod
    async def _save_audio_bytes(audio_data: bytes) -> str:
        """ä¿å­˜éŸ³é¢‘å­—èŠ‚æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶"""
        temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
        async with aiofiles.open(temp_file.name, 'wb') as f:
            await f.write(audio_data)
        
        logger.info(f"éŸ³é¢‘æ•°æ®ä¿å­˜æˆåŠŸ: {len(audio_data)} å­—èŠ‚ -> {temp_file.name}")
        return temp_file.name

    @staticmethod
    def validate_audio_file(file_path: str) -> bool:
        """éªŒè¯éŸ³é¢‘æ–‡ä»¶æ ¼å¼å’Œè´¨é‡"""
        try:
            waveform, sample_rate = torchaudio.load(file_path)
            
            # æ£€æŸ¥åŸºæœ¬å‚æ•°
            if waveform.numel() == 0:
                return False
            
            # æ£€æŸ¥æ—¶é•¿ (å»ºè®®3-30ç§’)
            duration = waveform.shape[1] / sample_rate
            if not (1.0 <= duration <= 60.0):
                logger.warning(f"éŸ³é¢‘æ—¶é•¿å¼‚å¸¸: {duration:.2f}ç§’")
            
            return True
        except Exception as e:
            logger.error(f"éŸ³é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            return False

    @staticmethod
    def load_wav(wav_path: str, target_sr: int = 16000):
        """
        åŠ è½½éŸ³é¢‘æ–‡ä»¶ - ä½¿ç”¨å®˜æ–¹CosyVoiceçš„æ–¹æ³•
        å‚è€ƒ: CosyVoice/cosyvoice/utils/file_utils.py::load_wav
        """
        try:
            import torchaudio
            
            speech, sample_rate = torchaudio.load(wav_path, backend='soundfile')
            speech = speech.mean(dim=0, keepdim=True)
            if sample_rate != target_sr:
                assert sample_rate > target_sr, f'wav sample rate {sample_rate} must be greater than {target_sr}'
                speech = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sr)(speech)
            return speech
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            raise ValueError(f"éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")

    @staticmethod
    def postprocess(speech, top_db=60, hop_length=220, win_length=440, max_val=0.8):
        """
        éŸ³é¢‘åå¤„ç† - ä½¿ç”¨å®˜æ–¹CosyVoiceçš„æ–¹æ³•
        å‚è€ƒ: CosyVoice/webui.py::postprocess
        """
        try:
            import librosa
            import torch
            
            speech, _ = librosa.effects.trim(
                speech, top_db=top_db,
                frame_length=win_length,
                hop_length=hop_length
            )
            if speech.abs().max() > max_val:
                speech = speech / speech.abs().max() * max_val
            
            # æ³¨æ„ï¼šè¿™é‡Œä¸æ·»åŠ å°¾éƒ¨é™éŸ³ï¼Œå› ä¸ºæˆ‘ä»¬æ˜¯ç”¨ä½œå‚è€ƒéŸ³é¢‘
            return speech
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘åå¤„ç†å¤±è´¥: {e}")
            raise ValueError(f"éŸ³é¢‘åå¤„ç†å¤±è´¥: {str(e)}")

    @staticmethod
    def load_audio_data(file_path: str, target_sample_rate: int = 16000):
        """åŠ è½½å¹¶å¤„ç†éŸ³é¢‘æ–‡ä»¶ä¸ºCosyVoice2æœŸæœ›çš„æ ¼å¼"""
        try:
            # ä½¿ç”¨å®˜æ–¹çš„æ–¹æ³•åŠ è½½éŸ³é¢‘
            speech = AudioFileHandler.load_wav(file_path, target_sample_rate)
            
            # ä½¿ç”¨å®˜æ–¹çš„åå¤„ç†æ–¹æ³•
            speech = AudioFileHandler.postprocess(speech)
            
            return speech
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            raise ValueError(f"éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")

class CosyVoice2Engine:
    """CosyVoice2 å¼•æ“ - ä¸“é—¨ä¼˜åŒ–çš„é«˜æ€§èƒ½å®ç°"""
    
    def __init__(self):
        self.config = get_config()
        self.cosyvoice = None
        self.model_type = None
        self.is_initialized = False
        self.capabilities = {
            'basic': False,
            'zero_shot': False,
            'cross_lingual': False,
            'instruct': False
        }
        
        # æ€§èƒ½ä¼˜åŒ–
        self._audio_cache = {}  # éŸ³é¢‘ç¼“å­˜
        self._speaker_cache = {}  # è¯´è¯äººç‰¹å¾ç¼“å­˜
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–CosyVoice2å¼•æ“"""
        try:
            logger.info("ğŸš€ åˆå§‹åŒ–CosyVoice2å¼•æ“...")
            
            # å¯¼å…¥CosyVoice
            from cosyvoice.cli.cosyvoice import CosyVoice2
            
            model_path = self.config.cosyvoice.model_path
            logger.info(f"ğŸ“ åŠ è½½æ¨¡å‹: {model_path}")
            
            # å¼‚æ­¥åŠ è½½æ¨¡å‹
            def _load_model():
                return CosyVoice2(model_path)
            
            self.cosyvoice = await asyncio.get_event_loop().run_in_executor(
                None, _load_model
            )
            
            # æ£€æµ‹æ¨¡å‹èƒ½åŠ›
            self._detect_capabilities()
            
            self.is_initialized = True
            logger.info("âœ… CosyVoice2å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"ğŸ¯ æ”¯æŒçš„åŠŸèƒ½: {list(k for k, v in self.capabilities.items() if v)}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ CosyVoice2å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _detect_capabilities(self):
        """æ£€æµ‹æ¨¡å‹æ”¯æŒçš„åŠŸèƒ½"""
        try:
            # CosyVoice2æ”¯æŒæ‰€æœ‰åŠŸèƒ½
            self.capabilities['basic'] = True
            self.capabilities['zero_shot'] = hasattr(self.cosyvoice, 'inference_zero_shot')
            self.capabilities['cross_lingual'] = hasattr(self.cosyvoice, 'inference_cross_lingual')
            
            # CosyVoice2ä½¿ç”¨inference_instruct2
            self.capabilities['instruct'] = hasattr(self.cosyvoice, 'inference_instruct2')
            
        except Exception as e:
            logger.error(f"åŠŸèƒ½æ£€æµ‹å¤±è´¥: {e}")
    
    async def synthesize(self, request: TTSRequest) -> TTSResult:
        """ä¸»åˆæˆæ–¹æ³• - æ ¹æ®æ¨¡å¼åˆ†å‘åˆ°ä¸åŒçš„å¤„ç†å‡½æ•°"""
        if not self.is_initialized:
            return TTSResult(
                success=False,
                error_message="å¼•æ“æœªåˆå§‹åŒ–",
                request_id=str(uuid.uuid4())
            )
        
        request_id = str(uuid.uuid4())
        
        try:
            # å¤„ç†å‚è€ƒéŸ³é¢‘
            if request.prompt_audio:
                prompt_audio_path = await AudioFileHandler.process_audio_input(request.prompt_audio)
                
                # éªŒè¯éŸ³é¢‘æ–‡ä»¶
                if not AudioFileHandler.validate_audio_file(prompt_audio_path):
                    return TTSResult(
                        success=False,
                        error_message="å‚è€ƒéŸ³é¢‘æ–‡ä»¶æ ¼å¼æ— æ•ˆ",
                        request_id=request_id
                    )
            else:
                prompt_audio_path = None
            
            # æ ¹æ®åˆæˆæ¨¡å¼é€‰æ‹©å¤„ç†æ–¹æ³•
            if request.mode == SynthesisMode.BASIC:
                result = await self._basic_synthesis(request, request_id)
            elif request.mode == SynthesisMode.ZERO_SHOT:
                result = await self._zero_shot_synthesis(request, request_id, prompt_audio_path)
            elif request.mode == SynthesisMode.CROSS_LINGUAL:
                result = await self._cross_lingual_synthesis(request, request_id, prompt_audio_path)
            elif request.mode == SynthesisMode.INSTRUCT:
                result = await self._instruct_synthesis(request, request_id)
            elif request.mode == SynthesisMode.INSTRUCT2:
                result = await self._instruct2_synthesis(request, request_id)
            elif request.mode == SynthesisMode.VOICE_CONVERSION:
                result = await self._voice_conversion(request, request_id)
            else:
                return TTSResult(
                    success=False,
                    error_message=f"ä¸æ”¯æŒçš„åˆæˆæ¨¡å¼: {request.mode}",
                    request_id=request_id
                )
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if prompt_audio_path and prompt_audio_path.startswith(tempfile.gettempdir()):
                try:
                    os.unlink(prompt_audio_path)
                except:
                    pass
            
            return result
            
        except Exception as e:
            logger.error(f"åˆæˆå¤±è´¥: {e}")
            return TTSResult(
                success=False,
                error_message=f"åˆæˆå¤±è´¥: {str(e)}",
                request_id=request_id
            )
    
    async def _basic_synthesis(self, request: TTSRequest, request_id: str) -> TTSResult:
        """åŸºç¡€è¯­éŸ³åˆæˆ - å¯¹äºCosyVoice2ï¼Œè¿™å®é™…ä¸Šæ˜¯é›¶æ ·æœ¬åˆæˆçš„é»˜è®¤ç‰ˆæœ¬"""
        def _synthesize():
            # CosyVoice2æ²¡æœ‰é¢„å®šä¹‰è¯´è¯äººï¼Œéœ€è¦ä½¿ç”¨é›¶æ ·æœ¬åˆæˆæ–¹å¼
            available_spks = self.cosyvoice.list_available_spks()
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºCosyVoice2æ¨¡å‹
            from cosyvoice.cli.model import CosyVoice2Model
            is_cosyvoice2 = isinstance(self.cosyvoice.model, CosyVoice2Model)
            
            if available_spks and not is_cosyvoice2:
                # ä¼ ç»ŸCosyVoiceï¼Œä½¿ç”¨SFTæ¨¡å¼
                speaker = request.speaker if request.speaker in available_spks else available_spks[0]
                for audio_output in self.cosyvoice.inference_sft(request.text, speaker):
                    return audio_output['tts_speech']
            else:
                # CosyVoice2æˆ–æ²¡æœ‰é¢„å®šä¹‰è¯´è¯äººï¼Œä½¿ç”¨é»˜è®¤éŸ³é¢‘è¿›è¡Œé›¶æ ·æœ¬åˆæˆ
                import os
                import numpy as np
                
                # åˆ›å»ºé»˜è®¤çš„é™éŸ³éŸ³é¢‘ä½œä¸ºå‚è€ƒï¼ˆå¦‚æœæ²¡æœ‰å…¶ä»–é€‰æ‹©ï¼‰
                default_audio_path = None
                
                # é¦–å…ˆå°è¯•ä½¿ç”¨ç°æœ‰çš„æµ‹è¯•éŸ³é¢‘
                for test_file in ["test_audio_better.wav", "test_audio_short.wav"]:
                    if os.path.exists(test_file):
                        default_audio_path = test_file
                        break
                
                if not default_audio_path:
                    # å¦‚æœæ²¡æœ‰æµ‹è¯•éŸ³é¢‘ï¼Œåˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„é™éŸ³éŸ³é¢‘
                    import tempfile
                    import torchaudio
                    
                    # ç”Ÿæˆ1ç§’çš„é™éŸ³éŸ³é¢‘ (16kHz)
                    silent_audio = torch.zeros(1, 16000)  # 1ç§’é™éŸ³
                    temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
                    torchaudio.save(temp_file.name, silent_audio, 16000)
                    default_audio_path = temp_file.name
                
                # åŠ è½½é»˜è®¤éŸ³é¢‘
                prompt_audio_data = AudioFileHandler.load_audio_data(default_audio_path)
                
                # ä½¿ç”¨é›¶æ ·æœ¬åˆæˆï¼Œä½¿ç”¨æœ€å°çš„æç¤ºæ–‡æœ¬
                for audio_output in self.cosyvoice.inference_zero_shot(
                    tts_text=request.text,
                    prompt_text="ä½ å¥½",  # æœ€å°æç¤ºæ–‡æœ¬
                    prompt_speech_16k=prompt_audio_data,
                    zero_shot_spk_id=request.speaker or ''
                ):
                    return audio_output['tts_speech']
        
        audio_tensor = await asyncio.get_event_loop().run_in_executor(None, _synthesize)
        return await self._process_audio_result(audio_tensor, request, request_id, SynthesisMode.BASIC)
    
    async def _zero_shot_synthesis(self, request: TTSRequest, request_id: str, prompt_audio_path: str) -> TTSResult:
        """é›¶æ ·æœ¬éŸ³è‰²å…‹éš†"""
        def _synthesize():
            # åŠ è½½éŸ³é¢‘æ•°æ®
            prompt_audio_data = AudioFileHandler.load_audio_data(prompt_audio_path)
            
            for audio_output in self.cosyvoice.inference_zero_shot(
                tts_text=request.text,
                prompt_text=request.prompt_text,
                prompt_speech_16k=prompt_audio_data,  # ä½¿ç”¨éŸ³é¢‘æ•°æ®
                zero_shot_spk_id=request.speaker or ''
            ):
                return audio_output['tts_speech']
        
        audio_tensor = await asyncio.get_event_loop().run_in_executor(None, _synthesize)
        return await self._process_audio_result(audio_tensor, request, request_id, SynthesisMode.ZERO_SHOT)
    
    async def _cross_lingual_synthesis(self, request: TTSRequest, request_id: str, prompt_audio_path: str) -> TTSResult:
        """è·¨è¯­è¨€åˆæˆ"""
        def _synthesize():
            # åŠ è½½éŸ³é¢‘æ•°æ®
            prompt_audio_data = AudioFileHandler.load_audio_data(prompt_audio_path)
            
            for audio_output in self.cosyvoice.inference_cross_lingual(
                tts_text=request.text,
                prompt_speech_16k=prompt_audio_data,  # ä½¿ç”¨éŸ³é¢‘æ•°æ®
                zero_shot_spk_id=request.speaker or ''
            ):
                return audio_output['tts_speech']
        
        audio_tensor = await asyncio.get_event_loop().run_in_executor(None, _synthesize)
        return await self._process_audio_result(audio_tensor, request, request_id, SynthesisMode.CROSS_LINGUAL)
    
    async def _instruct_synthesis(self, request: TTSRequest, request_id: str) -> TTSResult:
        """æŒ‡ä»¤å¼åˆæˆ"""
        # å¤„ç†å‚è€ƒéŸ³é¢‘ (CosyVoice2çš„æŒ‡ä»¤åˆæˆéœ€è¦å‚è€ƒéŸ³é¢‘)
        prompt_audio_path = None
        if request.prompt_audio:
            prompt_audio_path = await AudioFileHandler.process_audio_input(request.prompt_audio)
        else:
            # å¦‚æœæ²¡æœ‰æä¾›å‚è€ƒéŸ³é¢‘ï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„éŸ³é¢‘æ–‡ä»¶æˆ–ä½¿ç”¨é»˜è®¤
            # è¿™é‡Œæˆ‘ä»¬æŠ›å‡ºé”™è¯¯è¦æ±‚ç”¨æˆ·æä¾›å‚è€ƒéŸ³é¢‘
            raise ValueError("CosyVoice2çš„æŒ‡ä»¤å¼åˆæˆéœ€è¦æä¾›å‚è€ƒéŸ³é¢‘")
        
        try:
            def _synthesize():
                # åŠ è½½éŸ³é¢‘æ•°æ®
                prompt_audio_data = AudioFileHandler.load_audio_data(prompt_audio_path)
                
                # CosyVoice2ä½¿ç”¨inference_instruct2ï¼Œå‚æ•°: tts_text, instruct_text, prompt_speech_16k, zero_shot_spk_id, stream, speed, text_frontend
                for audio_output in self.cosyvoice.inference_instruct2(
                    tts_text=request.text,
                    instruct_text=request.instruct_text,
                    prompt_speech_16k=prompt_audio_data,  # ä½¿ç”¨éŸ³é¢‘æ•°æ®
                    zero_shot_spk_id=request.speaker or ''
                ):
                    return audio_output['tts_speech']
            
            audio_tensor = await asyncio.get_event_loop().run_in_executor(None, _synthesize)
            return await self._process_audio_result(audio_tensor, request, request_id, SynthesisMode.INSTRUCT)
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ - åªæ¸…ç†çœŸæ­£çš„ä¸´æ—¶æ–‡ä»¶ï¼Œä¿æŠ¤æµ‹è¯•æ–‡ä»¶
            if (prompt_audio_path and 
                prompt_audio_path.startswith(tempfile.gettempdir()) and
                not prompt_audio_path.endswith(('test_audio_better.wav', 'test_audio_short.wav'))):
                try:
                    os.unlink(prompt_audio_path)
                except:
                    pass
    
    async def _instruct2_synthesis(self, request: TTSRequest, request_id: str) -> TTSResult:
        """æŒ‡ä»¤å¼è¯­éŸ³åˆæˆ - CosyVoice2çš„è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼"""
        def _synthesize():
            # å¤„ç†å‚è€ƒéŸ³é¢‘
            prompt_audio_data = self._get_prompt_audio(request.prompt_audio)
            
            # ä½¿ç”¨CosyVoice2çš„inference_instruct2æ–¹æ³•
            for audio_output in self.cosyvoice.inference_instruct2(
                tts_text=request.text,
                instruct_text=request.instruct_text,
                prompt_speech_16k=prompt_audio_data,
                zero_shot_spk_id=request.zero_shot_spk_id,
                stream=False,
                speed=request.speed,
                text_frontend=request.text_frontend
            ):
                return audio_output['tts_speech']
        
        return await self._run_synthesis(_synthesize, request, request_id)
    
    async def _voice_conversion(self, request: TTSRequest, request_id: str) -> TTSResult:
        """è¯­éŸ³è½¬æ¢ - å°†æºéŸ³é¢‘è½¬æ¢ä¸ºç›®æ ‡éŸ³è‰²"""
        def _synthesize():
            # éœ€è¦æºéŸ³é¢‘å’Œç›®æ ‡éŸ³è‰²å‚è€ƒéŸ³é¢‘
            source_audio = self._get_prompt_audio(request.prompt_audio)  # æºéŸ³é¢‘
            target_audio = self._get_prompt_audio(request.prompt_audio)  # ç›®æ ‡éŸ³è‰²
            
            for audio_output in self.cosyvoice.inference_vc(
                source_speech_16k=source_audio,
                prompt_speech_16k=target_audio,
                stream=False,
                speed=request.speed
            ):
                return audio_output['tts_speech']
        
        return await self._run_synthesis(_synthesize, request, request_id)
    
    async def add_zero_shot_speaker(self, speaker_id: str, prompt_text: str, prompt_audio) -> bool:
        """æ·»åŠ é›¶æ ·æœ¬è¯´è¯äºº - ç”¨äºå…¨èƒ½API"""
        try:
            prompt_audio_data = self._get_prompt_audio(prompt_audio)
            success = self.cosyvoice.add_zero_shot_spk(
                prompt_text=prompt_text,
                prompt_speech_16k=prompt_audio_data,
                spk_id=speaker_id
            )
            if success:
                # ä¿å­˜è¯´è¯äººä¿¡æ¯
                self.cosyvoice.save_spkinfo()
                logger.info(f"âœ… ä¿å­˜é›¶æ ·æœ¬è¯´è¯äººæˆåŠŸ: {speaker_id}")
            return success
        except Exception as e:
            logger.error(f"æ·»åŠ é›¶æ ·æœ¬è¯´è¯äººå¤±è´¥: {e}")
            return False
    
    def get_saved_speakers(self):
        """è·å–å·²ä¿å­˜çš„è¯´è¯äººåˆ—è¡¨ - ç”¨äºå…¨èƒ½API"""
        try:
            # è·å–é›¶æ ·æœ¬è¯´è¯äººä¿¡æ¯
            spk_info = getattr(self.cosyvoice.frontend, 'spk2info', {})
            saved_speakers = {}
            
            for spk_id, info in spk_info.items():
                if isinstance(spk_id, str) and not spk_id.isdigit():  # æ’é™¤é¢„è®­ç»ƒéŸ³è‰²
                    saved_speakers[spk_id] = {
                        "id": spk_id,
                        "type": "zero_shot",
                        "embedding_shape": info.get('llm_embedding', torch.tensor([])).shape if 'llm_embedding' in info else None
                    }
            
            return saved_speakers
        except Exception as e:
            logger.error(f"è·å–ä¿å­˜è¯´è¯äººå¤±è´¥: {e}")
            return {}
    
    async def _process_audio_result(self, audio_tensor: torch.Tensor, request: TTSRequest, 
                                  request_id: str, mode: SynthesisMode) -> TTSResult:
        """å¤„ç†éŸ³é¢‘ç»“æœï¼Œåº”ç”¨åå¤„ç†å’Œæ ¼å¼è½¬æ¢"""
        try:
            # åº”ç”¨è¯­é€Ÿè°ƒæ•´
            if request.speed != 1.0:
                try:
                    import scipy.signal
                    audio_np = audio_tensor.cpu().numpy()
                    new_length = int(audio_np.shape[1] / request.speed)
                    if new_length > 0:
                        resampled = scipy.signal.resample(audio_np, new_length, axis=1)
                        audio_tensor = torch.from_numpy(resampled).float()
                except Exception as e:
                    logger.warning(f"è¯­é€Ÿè°ƒæ•´å¤±è´¥: {e}")
            
            # é‡é‡‡æ ·
            sample_rate = getattr(self.cosyvoice, 'sample_rate', 22050)
            target_sample_rate = request.sample_rate or sample_rate
            
            if sample_rate != target_sample_rate:
                try:
                    resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)
                    audio_tensor = resampler(audio_tensor)
                    sample_rate = target_sample_rate
                except Exception as e:
                    logger.warning(f"é‡é‡‡æ ·å¤±è´¥: {e}")
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            output_file = os.path.join(
                self.config.file.output_dir,
                f"{request_id}.{request.format.value}"
            )
            
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            # æ ¹æ®æ ¼å¼ä¿å­˜
            if request.format == AudioFormat.WAV:
                torchaudio.save(output_file, audio_tensor, sample_rate, format="wav")
            elif request.format == AudioFormat.MP3:
                torchaudio.save(output_file, audio_tensor, sample_rate, format="mp3")
            elif request.format == AudioFormat.FLAC:
                torchaudio.save(output_file, audio_tensor, sample_rate, format="flac")
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_size = os.path.getsize(output_file)
            duration = audio_tensor.shape[1] / sample_rate
            
            return TTSResult(
                success=True,
                audio_file=output_file,
                duration=duration,
                file_size=file_size,
                sample_rate=sample_rate,
                request_id=request_id,
                mode_used=mode
            )
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
            return TTSResult(
                success=False,
                error_message=f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}",
                request_id=request_id
            )
    
    async def synthesize_stream(self, request: TTSRequest) -> AsyncGenerator[bytes, None]:
        """æµå¼åˆæˆ - è¿”å›éŸ³é¢‘æ•°æ®æµ"""
        if not self.is_initialized:
            raise RuntimeError("å¼•æ“æœªåˆå§‹åŒ–")
        
        # å¤„ç†å‚è€ƒéŸ³é¢‘
        prompt_audio_path = None
        if request.prompt_audio:
            prompt_audio_path = await AudioFileHandler.process_audio_input(request.prompt_audio)
        
        # ç”¨äºæ¸…ç†çš„è·¯å¾„å˜é‡
        cleanup_path = prompt_audio_path
        
        try:
            def _stream_synthesize():
                nonlocal cleanup_path, prompt_audio_path
                if request.mode == SynthesisMode.BASIC:
                    # ä¸åŸºç¡€åˆæˆç›¸åŒçš„é€»è¾‘
                    available_spks = self.cosyvoice.list_available_spks()
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºCosyVoice2æ¨¡å‹
                    from cosyvoice.cli.model import CosyVoice2Model
                    is_cosyvoice2 = isinstance(self.cosyvoice.model, CosyVoice2Model)
                    
                    if available_spks and not is_cosyvoice2:
                        # ä¼ ç»ŸCosyVoiceï¼Œä½¿ç”¨SFTæ¨¡å¼
                        speaker = request.speaker if request.speaker in available_spks else available_spks[0]
                        return self.cosyvoice.inference_sft(request.text, speaker)
                    else:
                        # CosyVoice2æˆ–æ²¡æœ‰é¢„å®šä¹‰è¯´è¯äººï¼Œä½¿ç”¨é»˜è®¤éŸ³é¢‘è¿›è¡Œé›¶æ ·æœ¬åˆæˆ
                        import os
                        import numpy as np
                        
                        # åˆ›å»ºé»˜è®¤çš„é™éŸ³éŸ³é¢‘ä½œä¸ºå‚è€ƒï¼ˆå¦‚æœæ²¡æœ‰å…¶ä»–é€‰æ‹©ï¼‰
                        default_audio_path = None
                        
                        # é¦–å…ˆå°è¯•ä½¿ç”¨ç°æœ‰çš„æµ‹è¯•éŸ³é¢‘
                        for test_file in ["test_audio_better.wav", "test_audio_short.wav"]:
                            if os.path.exists(test_file):
                                default_audio_path = test_file
                                break
                        
                        if not default_audio_path:
                            # å¦‚æœæ²¡æœ‰æµ‹è¯•éŸ³é¢‘ï¼Œåˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„é™éŸ³éŸ³é¢‘
                            import tempfile
                            import torchaudio
                            
                            # ç”Ÿæˆ1ç§’çš„é™éŸ³éŸ³é¢‘ (16kHz)
                            silent_audio = torch.zeros(1, 16000)  # 1ç§’é™éŸ³
                            temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
                            torchaudio.save(temp_file.name, silent_audio, 16000)
                            default_audio_path = temp_file.name
                        
                        prompt_audio_data = AudioFileHandler.load_audio_data(default_audio_path)
                        return self.cosyvoice.inference_zero_shot(
                            tts_text=request.text,
                            prompt_text="ä½ å¥½",  # æœ€å°æç¤ºæ–‡æœ¬
                            prompt_speech_16k=prompt_audio_data,
                            zero_shot_spk_id=request.speaker or ''
                        )
                elif request.mode == SynthesisMode.ZERO_SHOT:
                    # ç¡®ä¿æœ‰å‚è€ƒéŸ³é¢‘æ–‡ä»¶
                    if not prompt_audio_path:
                        import os
                        default_audio_path = "test_audio_better.wav"
                        if not os.path.exists(default_audio_path):
                            default_audio_path = "test_audio_short.wav"
                        if not os.path.exists(default_audio_path):
                            raise ValueError("é›¶æ ·æœ¬åˆæˆéœ€è¦å‚è€ƒéŸ³é¢‘æ–‡ä»¶")
                        prompt_audio_path = default_audio_path
                    
                    prompt_audio_data = AudioFileHandler.load_audio_data(prompt_audio_path)
                    return self.cosyvoice.inference_zero_shot(
                        tts_text=request.text, 
                        prompt_text=request.prompt_text or "è¿™æ˜¯ä¸€ä¸ªæ ‡å‡†çš„ä¸­æ–‡è¯­éŸ³ã€‚", 
                        prompt_speech_16k=prompt_audio_data,
                        zero_shot_spk_id=request.speaker or ''
                    )
                elif request.mode == SynthesisMode.CROSS_LINGUAL:
                    # ç¡®ä¿æœ‰å‚è€ƒéŸ³é¢‘æ–‡ä»¶
                    if not prompt_audio_path:
                        import os
                        default_audio_path = "test_audio_better.wav"
                        if not os.path.exists(default_audio_path):
                            default_audio_path = "test_audio_short.wav"
                        if not os.path.exists(default_audio_path):
                            raise ValueError("è·¨è¯­è¨€åˆæˆéœ€è¦å‚è€ƒéŸ³é¢‘æ–‡ä»¶")
                        prompt_audio_path = default_audio_path
                    
                    prompt_audio_data = AudioFileHandler.load_audio_data(prompt_audio_path)
                    return self.cosyvoice.inference_cross_lingual(
                        tts_text=request.text, 
                        prompt_speech_16k=prompt_audio_data,
                        zero_shot_spk_id=request.speaker or ''
                    )
                elif request.mode == SynthesisMode.INSTRUCT:
                    # ç¡®ä¿æœ‰å‚è€ƒéŸ³é¢‘æ–‡ä»¶
                    if not prompt_audio_path:
                        import os
                        default_audio_path = "test_audio_better.wav"
                        if not os.path.exists(default_audio_path):
                            default_audio_path = "test_audio_short.wav"
                        if not os.path.exists(default_audio_path):
                            raise ValueError("æŒ‡ä»¤å¼åˆæˆéœ€è¦å‚è€ƒéŸ³é¢‘æ–‡ä»¶")
                        prompt_audio_path = default_audio_path
                    
                    prompt_audio_data = AudioFileHandler.load_audio_data(prompt_audio_path)
                    return self.cosyvoice.inference_instruct2(
                        tts_text=request.text, 
                        instruct_text=request.instruct_text or "è¯·ç”¨è‡ªç„¶çš„è¯­è°ƒæœ—è¯»ã€‚", 
                        prompt_speech_16k=prompt_audio_data,
                        zero_shot_spk_id=request.speaker or ''
                    )
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œæµå¼åˆæˆ
            audio_output = await asyncio.get_event_loop().run_in_executor(None, _stream_synthesize)
            
            # CosyVoiceå¯èƒ½è¿”å›ç”Ÿæˆå™¨æˆ–å­—å…¸ï¼Œéœ€è¦å¤„ç†
            if hasattr(audio_output, '__iter__') and not isinstance(audio_output, dict):
                # å¦‚æœæ˜¯ç”Ÿæˆå™¨ï¼Œå–ç¬¬ä¸€ä¸ªç»“æœ
                audio_output = next(iter(audio_output))
            
            audio_tensor = audio_output['tts_speech']
            
            # è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
            import io
            buffer = io.BytesIO()
            sample_rate = getattr(self.cosyvoice, 'sample_rate', 22050)
            torchaudio.save(buffer, audio_tensor, sample_rate, format="wav")
            
            # åˆ†å—è¿”å›éŸ³é¢‘æ•°æ®ï¼ˆæ¨¡æ‹Ÿæµå¼ï¼‰
            audio_bytes = buffer.getvalue()
            chunk_size = 8192  # 8KB å—
            
            for i in range(0, len(audio_bytes), chunk_size):
                yield audio_bytes[i:i + chunk_size]
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ - åªæ¸…ç†çœŸæ­£çš„ä¸´æ—¶æ–‡ä»¶ï¼Œä¿æŠ¤æµ‹è¯•æ–‡ä»¶
            if (cleanup_path and 
                cleanup_path.startswith(tempfile.gettempdir()) and
                not cleanup_path.endswith(('test_audio_better.wav', 'test_audio_short.wav'))):
                try:
                    os.unlink(cleanup_path)
                except:
                    pass
    
    def get_available_speakers(self) -> List[str]:
        """è·å–å¯ç”¨éŸ³è‰²åˆ—è¡¨"""
        # CosyVoice2é‡‡ç”¨é›¶æ ·æœ¬è®¾è®¡ï¼Œè¿”å›å»ºè®®çš„é»˜è®¤éŸ³è‰²åç§°
        return ["neutral", "female", "male"]
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, '_audio_cache'):
            self._audio_cache.clear()
        if hasattr(self, '_speaker_cache'):
            self._speaker_cache.clear()

    def _get_prompt_audio(self, prompt_audio):
        """è·å–å‚è€ƒéŸ³é¢‘æ•°æ®"""
        if prompt_audio is None:
            # ä½¿ç”¨é»˜è®¤éŸ³é¢‘
            import os
            for test_file in ["test_audio_better.wav", "test_audio_short.wav"]:
                if os.path.exists(test_file):
                    return AudioFileHandler.load_audio_data(test_file)
            
            # å¦‚æœæ²¡æœ‰æµ‹è¯•éŸ³é¢‘ï¼Œåˆ›å»ºé™éŸ³éŸ³é¢‘
            import tempfile
            import torchaudio
            silent_audio = torch.zeros(1, 16000)  # 1ç§’é™éŸ³
            temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
            torchaudio.save(temp_file.name, silent_audio, 16000)
            return AudioFileHandler.load_audio_data(temp_file.name)
        
        if isinstance(prompt_audio, str):
            # æ–‡ä»¶è·¯å¾„æˆ–URL
            return AudioFileHandler.load_audio_data(prompt_audio)
        elif isinstance(prompt_audio, bytes):
            # éŸ³é¢‘å­—èŠ‚æ•°æ®
            import tempfile
            temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
            temp_file.write(prompt_audio)
            temp_file.close()
            return AudioFileHandler.load_audio_data(temp_file.name)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘è¾“å…¥ç±»å‹: {type(prompt_audio)}")
    
    async def _run_synthesis(self, synthesize_func, request: TTSRequest, request_id: str) -> TTSResult:
        """è¿è¡Œåˆæˆå‡½æ•°çš„é€šç”¨æ–¹æ³•"""
        try:
            audio_tensor = await asyncio.get_event_loop().run_in_executor(None, synthesize_func)
            return await self._process_audio_result(audio_tensor, request, request_id, request.mode)
        except Exception as e:
            logger.error(f"åˆæˆå¤±è´¥: {e}")
            return TTSResult(
                success=False,
                error_message=f"åˆæˆå¤±è´¥: {str(e)}",
                request_id=request_id
            )

class CosyVoice2Service:
    """CosyVoice2 é«˜æ€§èƒ½TTSæœåŠ¡"""
    
    def __init__(self):
        self.engine = CosyVoice2Engine()
        self.custom_speakers = {}  # è‡ªå®šä¹‰éŸ³è‰²å­˜å‚¨
        self.config = get_config()
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–æœåŠ¡"""
        logger.info("ğŸš€ åˆå§‹åŒ–CosyVoice2æœåŠ¡...")
        success = await self.engine.initialize()
        
        if success:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(self.config.file.output_dir, exist_ok=True)
            logger.info("âœ… CosyVoice2æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        
        return success
    
    async def synthesize(self, request: TTSRequest) -> TTSResult:
        """è¯­éŸ³åˆæˆ"""
        return await self.engine.synthesize(request)
    
    async def synthesize_stream(self, request: TTSRequest) -> AsyncGenerator[bytes, None]:
        """æµå¼è¯­éŸ³åˆæˆ"""
        async for chunk in self.engine.synthesize_stream(request):
            yield chunk
    
    async def add_custom_speaker(self, speaker_name: str, prompt_text: str, 
                               prompt_audio: Union[str, bytes], description: str = None) -> dict:
        """æ·»åŠ è‡ªå®šä¹‰éŸ³è‰²"""
        try:
            # å¤„ç†éŸ³é¢‘è¾“å…¥
            prompt_audio_path = await AudioFileHandler.process_audio_input(prompt_audio)
            
            # éªŒè¯éŸ³é¢‘
            if not AudioFileHandler.validate_audio_file(prompt_audio_path):
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if prompt_audio_path and prompt_audio_path.startswith(tempfile.gettempdir()):
                    try:
                        os.unlink(prompt_audio_path)
                    except:
                        pass
                return {"success": False, "error": "éŸ³é¢‘æ–‡ä»¶æ ¼å¼æ— æ•ˆ"}
            
            # ç”ŸæˆéŸ³è‰²ID
            speaker_id = hashlib.md5(f"{speaker_name}_{prompt_text}".encode()).hexdigest()[:16]
            
            # å¦‚æœæ˜¯å›ºå®šæµ‹è¯•æ–‡ä»¶ï¼Œä¸éœ€è¦å¤åˆ¶
            if isinstance(prompt_audio, str) and not prompt_audio.startswith(('http://', 'https://')):
                # ç›´æ¥ä½¿ç”¨æœ¬åœ°æ–‡ä»¶è·¯å¾„
                if os.path.exists(prompt_audio):
                    final_audio_path = prompt_audio
                else:
                    final_audio_path = prompt_audio_path
            else:
                # ä¸ºä¸Šä¼ çš„éŸ³é¢‘åˆ›å»ºæ°¸ä¹…å‰¯æœ¬
                import shutil
                permanent_path = f"custom_speakers/{speaker_id}.wav"
                os.makedirs("custom_speakers", exist_ok=True)
                shutil.copy2(prompt_audio_path, permanent_path)
                final_audio_path = permanent_path
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if prompt_audio_path.startswith(tempfile.gettempdir()):
                    try:
                        os.unlink(prompt_audio_path)
                    except:
                        pass
            
            # ä¿å­˜è‡ªå®šä¹‰éŸ³è‰²ä¿¡æ¯
            self.custom_speakers[speaker_id] = {
                "speaker_name": speaker_name,
                "speaker_id": speaker_id,
                "prompt_text": prompt_text,
                "prompt_audio_path": final_audio_path,
                "description": description or f"è‡ªå®šä¹‰éŸ³è‰²: {speaker_name}",
                "created_at": str(uuid.uuid4())
            }
            
            logger.info(f"âœ… è‡ªå®šä¹‰éŸ³è‰²æ·»åŠ æˆåŠŸ: {speaker_name} -> {speaker_id}")
            return {"success": True, "speaker_id": speaker_id}
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ è‡ªå®šä¹‰éŸ³è‰²å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def get_custom_speakers(self) -> list:
        """è·å–è‡ªå®šä¹‰éŸ³è‰²åˆ—è¡¨"""
        return list(self.custom_speakers.values())
    
    async def delete_custom_speaker(self, speaker_id: str) -> dict:
        """åˆ é™¤è‡ªå®šä¹‰éŸ³è‰²"""
        try:
            if speaker_id in self.custom_speakers:
                speaker_info = self.custom_speakers[speaker_id]
                
                # æ¸…ç†éŸ³é¢‘æ–‡ä»¶ - ä½†ä¸åˆ é™¤æµ‹è¯•æ–‡ä»¶
                audio_path = speaker_info.get("prompt_audio_path")
                if (audio_path and os.path.exists(audio_path) and
                    not audio_path.endswith(('test_audio_better.wav', 'test_audio_short.wav'))):
                    try:
                        os.unlink(audio_path)
                    except:
                        pass
                
                # åˆ é™¤è®°å½•
                del self.custom_speakers[speaker_id]
                
                logger.info(f"âœ… è‡ªå®šä¹‰éŸ³è‰²åˆ é™¤æˆåŠŸ: {speaker_id}")
                return {"success": True}
            else:
                return {"success": False, "error": "éŸ³è‰²ä¸å­˜åœ¨"}
                
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤è‡ªå®šä¹‰éŸ³è‰²å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def get_engine_status(self) -> dict:
        """è·å–å¼•æ“çŠ¶æ€"""
        return {
            "initialized": self.engine.is_initialized,
            "capabilities": self.engine.capabilities,
            "model_path": self.config.cosyvoice.model_path,
            "custom_speakers_count": len(self.custom_speakers)
        }
    
    def get_available_speakers(self) -> List[str]:
        """è·å–å¯ç”¨éŸ³è‰²"""
        return self.engine.get_available_speakers()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.engine.cleanup()
        
        # æ¸…ç†è‡ªå®šä¹‰éŸ³è‰²æ–‡ä»¶ - ä½†ä¸åˆ é™¤æµ‹è¯•æ–‡ä»¶
        for speaker_info in self.custom_speakers.values():
            audio_path = speaker_info.get("prompt_audio_path")
            if (audio_path and os.path.exists(audio_path) and
                not audio_path.endswith(('test_audio_better.wav', 'test_audio_short.wav'))):
                try:
                    os.unlink(audio_path)
                except:
                    pass
        
        self.custom_speakers.clear()

    async def add_zero_shot_speaker(self, speaker_id: str, prompt_text: str, prompt_audio) -> bool:
        """æ·»åŠ é›¶æ ·æœ¬è¯´è¯äºº - ç”¨äºå…¨èƒ½API"""
        return await self.engine.add_zero_shot_speaker(speaker_id, prompt_text, prompt_audio)
    
    def get_saved_speakers(self):
        """è·å–å·²ä¿å­˜çš„è¯´è¯äººåˆ—è¡¨ - ç”¨äºå…¨èƒ½API"""
        return self.engine.get_saved_speakers()

# å…¨å±€æœåŠ¡å®ä¾‹
_service_instance = None

def get_cosyvoice2_service() -> CosyVoice2Service:
    """è·å–CosyVoice2æœåŠ¡å•ä¾‹"""
    global _service_instance
    if _service_instance is None:
        _service_instance = CosyVoice2Service()
    return _service_instance

# å…¼å®¹æ€§å‡½æ•°
def get_tts_service() -> CosyVoice2Service:
    """å…¼å®¹æ€§å‡½æ•°"""
    return get_cosyvoice2_service()

if __name__ == "__main__":
    async def test_service():
        """æµ‹è¯•æœåŠ¡"""
        service = get_cosyvoice2_service()
        
        # åˆå§‹åŒ–
        success = await service.initialize()
        if not success:
            print("âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥")
            return
        
        # åŸºç¡€åˆæˆæµ‹è¯•
        request = TTSRequest(
            text="è¿™æ˜¯CosyVoice2çš„åŸºç¡€è¯­éŸ³åˆæˆæµ‹è¯•ã€‚",
            mode=SynthesisMode.BASIC
        )
        
        result = await service.synthesize(request)
        if result.success:
            print(f"âœ… åŸºç¡€åˆæˆæˆåŠŸ: {result.audio_file}")
        else:
            print(f"âŒ åŸºç¡€åˆæˆå¤±è´¥: {result.error_message}")
    
    asyncio.run(test_service())